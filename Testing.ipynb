{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Testeo"
      ],
      "metadata": {
        "id": "JHGsaZcSM5dT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#instalaciones requeridas\n",
        "!pip install reverse_geocode\n",
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "!pip install roboflow\n",
        "!pip install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ei80GmTaOeTV",
        "outputId": "c59a5e9e-5e24-482b-8fda-849416274a46"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: reverse_geocode in /usr/local/lib/python3.10/dist-packages (1.6.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from reverse_geocode) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from reverse_geocode) (1.11.4)\n",
            "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-2uvos_de\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-2uvos_de\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit 2a420edb307c9bdf640f036d3b196bed474b8593\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (9.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (3.7.1)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.4.0)\n",
            "Requirement already satisfied: yacs>=0.1.8 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.1.8)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.2.1)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (4.66.4)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.15.2)\n",
            "Collecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.6)\n",
            "  Using cached fvcore-0.1.5.post20221221-py3-none-any.whl\n",
            "Collecting iopath<0.1.10,>=0.1.7 (from detectron2==0.6)\n",
            "  Using cached iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.3.0)\n",
            "Collecting hydra-core>=1.1 (from detectron2==0.6)\n",
            "  Using cached hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "Collecting black (from detectron2==0.6)\n",
            "  Using cached black-24.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (24.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.25.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.1)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.1->detectron2==0.6) (4.9.3)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from iopath<0.1.10,>=0.1.7->detectron2==0.6) (2.10.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (8.1.7)\n",
            "Collecting mypy-extensions>=0.4.3 (from black->detectron2==0.6)\n",
            "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (4.2.2)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (4.12.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.64.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->detectron2==0.6) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->detectron2==0.6) (3.2.2)\n",
            "Building wheels for collected packages: detectron2\n",
            "  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for detectron2: filename=detectron2-0.6-cp310-cp310-linux_x86_64.whl size=6174366 sha256=6de31b9e889bd84a63920fcf75ebfeb9d46daae5eff5b669b1f2915a60b8f58a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-16azy01n/wheels/47/e5/15/94c80df2ba85500c5d76599cc307c0a7079d0e221bb6fc4375\n",
            "Successfully built detectron2\n",
            "Installing collected packages: mypy-extensions, iopath, hydra-core, fvcore, black, detectron2\n",
            "Successfully installed black-24.4.2 detectron2-0.6 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 mypy-extensions-1.0.0\n",
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.10/dist-packages (1.1.36)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from roboflow) (2024.7.4)\n",
            "Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.0.0)\n",
            "Requirement already satisfied: idna==3.7 in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.25.2)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.4)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.53.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.36.0-py2.py3-none-any.whl (8.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.4.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.25.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.0.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog<5,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-4.0.1-py3-none-manylinux2014_x86_64.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.7.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.19.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "Installing collected packages: watchdog, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 pydeck-0.9.1 smmap-5.0.1 streamlit-1.36.0 watchdog-4.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Librerías\n",
        "\n",
        "#De uso general\n",
        "import os #Para funcionalidades dependientes del sistema operativo\n",
        "import cv2 #Para el procesamiento de imágenes\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt #Para crear gráficos\n",
        "import numpy as np #Para operar funciones, vectores y matrices\n",
        "import pandas as pd #Para manipulación y análisis de datos\n",
        "from PIL import Image #Para abrir, manipular y guardar imágenes en varios formatos\n",
        "import streamlit as st #Para la creación de aplicaciones web interactivas\n",
        "\n",
        "#Conjunto de librerías para geolocalización\n",
        "import reverse_geocode #Para convertir coordenadas geográficas (latitud y longitud) en direcciones o nombres de lugares\n",
        "import folium #Para la creación de mapas interactivos\n",
        "from IPython.display import display\n",
        "\n",
        "%matplotlib inline\n",
        "#Conjunto de librerías para la detección de objetos\n",
        "import torch #ML basada en el cálculo automático de gradientes y en redes neuronales profundas.\n",
        "import detectron2 #Detección de objetos.\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "from detectron2.engine import DefaultTrainer\n",
        "import logging #Para registrar eventos y mensajes durante la ejecución del programa\n",
        "from detectron2.utils.logger import setup_logger\n",
        "from roboflow import Roboflow #Ofrece datasets y herramientas para el entrenamiento de modelos\n"
      ],
      "metadata": {
        "id": "0QVF6lTPH3EB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir el estilo CSS para el color de fondo\n",
        "color_reto = \"#FFD700\"  # Amarillo\n",
        "color_defi = \"#ADD8E6\"  # Azul claro\n",
        "color_ries_con = \"#90EE90\"  # Verde claro\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        ".centered {\n",
        "    text-align: center;\n",
        "}\n",
        "</style>\n",
        "<div class=\"centered\">\n",
        "    <h1>MonomerFinder: Identificación de microplásticos en imágenes</h1>\n",
        "</div>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# Menú desplegable para \"¿Qué es MonomerFinder?\"\n",
        "with st.expander(\"¿Qué es MonomerFinder?\"):\n",
        "    st.markdown(f\"<div style='background-color:{color_reto}; padding: 5px; border-radius: 5px;'>\", unsafe_allow_html=True)\n",
        "    st.write(\"MonomerFinder es una aplicación que facilita la identificación y clasificación de microplásticos presentes en imágenes capturadas por los propios usuarios. Para esto utiliza una IA que se encarga de analizar las imágenes y señalar la cantidad de microplásticos presentes y su tipo. Esta aplicación es el resultado del Reto 5 del Hackaton Coafina 2024: 'Microplásticos: un desafío ciudadano'.\")\n",
        "    st.markdown(\"</div>\", unsafe_allow_html=True)\n",
        "\n",
        "# Menú desplegable para \"¿Qué son los microplásticos?\"\n",
        "with st.expander(\"¿Qué son los microplásticos?\"):\n",
        "    st.markdown(f\"<div style='background-color:{color_defi}; padding: 5px; border-radius: 5px;'>\", unsafe_allow_html=True)\n",
        "    st.write(\"Los microplásticos son diminutas partículas de plástico, generalmente con tamaños menores a 5 mm, que se han convertido en un problema ambiental global. Provienen de diversas fuentes, como la degradación de objetos plásticos más grandes, productos cosméticos y fibras sintéticas de la ropa. Estos diminutos fragmentos contaminan océanos, ríos, suelos e incluso el aire, siendo ingeridos por organismos marinos y terrestres, lo que puede llevar a su acumulación en la cadena alimentaria. Su persistencia en el medio ambiente y sus potenciales efectos negativos en la salud humana y de los ecosistemas son motivo de creciente preocupación entre científicos y ambientalistas.\")\n",
        "    st.markdown(\"</div>\", unsafe_allow_html=True)\n",
        "\n",
        "# Menú desplegable adicional para \"Fuentes de microplásticos\"\n",
        "with st.expander(\"Fuentes de microplásticos\"):\n",
        "    st.markdown(f\"<div style='background-color:{color_ries_con}; padding: 5px; border-radius: 5px;'>\", unsafe_allow_html=True)\n",
        "    st.write(\"Los microplásticos pueden provenir de diversas fuentes, entre las que se destacan:\")\n",
        "    st.write(\"- Textiles:  El 70% de los textiles producidos hoy en día son de origen sintético y liberan grandes cantidades de microplásticos al medio ambiente. La liberación de fibras y sustancias sintéticas de la ropa se produce no solo a través del lavado y el uso, sino también durante la producción, el procesamiento y el transporte. Los geotextiles, que se utilizan comúnmente para sostener y reforzar las capas del suelo o como manto agrícola, también liberan microplásticos debido a la exposición a los rayos UV, daños físicos y un mantenimiento deficiente.\")\n",
        "    st.write(\"- Cosméticos y productos de cuidado personal: Un gran número de productos de cuidado personal todavía contienen microplásticos añadidos intencionadamente (por ejemplo, escarcha, microperlas en exfoliantes faciales y corporales). Estos productos ingresan al sistema de alcantarillado y a las plantas de tratamiento de aguas residuales. Aquí no se eliminan por completo y, por lo tanto, ingresan al medio ambiente.\")\n",
        "    st.write(\"- Pesca y acuicultura: Los microplásticos son liberados por: aguas grises de los buques que desembocan sin filtrar en el mar, la degradación de las líneas de pesca perdidas, pinturas y revestimientos marinos, residuos plásticos de un solo uso procedentes de la pesca y la acuicultura, y pérdida de contenedores marítimos con productos plásticos.\")\n",
        "    st.write(\"- Agricultura: Diversas fuentes agrícolas contribuyen a la propagación de microplásticos en el suelo, por ejemplo, a través de: el uso generalizado de películas de cultivo, tuberías de riego, comprimidos nutritivos, recubrimientos de semillas, lodos de depuradora de plantas de tratamiento de aguas residuales utilizados como fertilizante del suelo. Dado que la mitad de todos los lodos de depuradora de europa acaban de nuevo en tierra, se trata de un problema generalizado.\")\n",
        "    st.write(\"- Tráfico: La abrasión de los neumáticos, las marcas viales y los escombros de la carretera son fuentes de microplásticos ambientales. Se estima que solo la abrasión de los neumáticos genera más de 1,3 millones de toneladas de microplásticos en Europa cada año. El 'reciclaje' de neumáticos usados suele ser problemático, ya que los microplásticos se liberan directamente al medio ambiente a través de su uso en arrecifes artificiales, campos deportivos o patios escolares.\")\n",
        "    st.write(\"- Procesamiento de plásticos: Los pellets son perlas de plástico nuevas o recicladas que se utilizan como materia prima en la fabricación de la mayoría de los productos plásticos. Sin embargo, las pérdidas de gránulos, escamas y polvo de plástico se producen a lo largo de toda la cadena de valor de la producción, el transporte y el reciclaje de plástico. Además, el agua del proceso y las aguas residuales de la industria del plástico pueden estar muy contaminadas con microplásticos.\")\n",
        "    st.write(\"- Turismo: La eliminación inadecuada de los residuos de los turistas, los sistemas locales de gestión de residuos deficientes o inexistentes, la descarga incontrolada de aguas residuales de los cruceros y el consumo masivo de productos y envases de plástico de un solo uso en los países impulsados por el turismo, aumentan los aportes de microplásticos.\")\n",
        "\n",
        "    st.markdown(\"</div>\", unsafe_allow_html=True)\n",
        "\n",
        "# Software de MonomerFinder\n",
        "st.write(\"\"\"\n",
        "<style>\n",
        ".centered {\n",
        "    text-align: center;\n",
        "}\n",
        "</style>\n",
        "<div class=\"centered\">\n",
        "    <h1>¡Vamos a identificar y contar microplásticos!</h1>\n",
        "</div>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "st.write(\"Recuerda:\")\n",
        "st.write(\"1-.Tener a la mano tu ubicación\")\n",
        "st.write(\"2-.La fotos deben ser de microplásticos filtrados es decir sin ningún otro material en lo posible\")\n",
        "st.write(\"3-.Las fotos deben ser claras para obtener mejores resultados\")\n",
        "\n",
        "# Solicitar al usuario que ingrese el nombre del archivo de imagen\n",
        "st.markdown(\"\"\"\n",
        "    <style>\n",
        "    .center {\n",
        "        display: flex;\n",
        "        justify-content: center;\n",
        "    }\n",
        "    </style>\n",
        "    <div class=\"center\">\n",
        "        <h2>Sube tu imagen</h2>\n",
        "    </div>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "uploaded_file = st.file_uploader(\" \", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "#Descarga y configuración del dataset\n",
        "rf = Roboflow(api_key=\"Dlwgwe3psTHRPIuQlsbV\")\n",
        "project = rf.workspace(\"panats-mp-project\").project(\"microplastic-dataset\")\n",
        "dataset = project.version(19).download(\"coco\")\n",
        "\n",
        "#Definición de rutas y nombres\n",
        "DATA_SET_NAME = dataset.name.replace(\" \", \"-\")\n",
        "ANNOTATIONS_FILE_NAME = \"_annotations.coco.json\"\n",
        "\n",
        "#Registro del dataset\n",
        "TRAIN_DATA_SET_NAME = f\"{DATA_SET_NAME}-train\"\n",
        "TRAIN_DATA_SET_IMAGES_DIR_PATH = os.path.join(dataset.location, \"train\")\n",
        "TRAIN_DATA_SET_ANN_FILE_PATH = os.path.join(dataset.location, \"train\", ANNOTATIONS_FILE_NAME)\n",
        "\n",
        "register_coco_instances(\n",
        "    name=TRAIN_DATA_SET_NAME,\n",
        "    metadata={},\n",
        "    json_file=TRAIN_DATA_SET_ANN_FILE_PATH,\n",
        "    image_root=TRAIN_DATA_SET_IMAGES_DIR_PATH\n",
        ")\n",
        "\n",
        "#Validación del dataset\n",
        "VALID_DATA_SET_NAME = f\"{DATA_SET_NAME}-valid\"\n",
        "VALID_DATA_SET_IMAGES_DIR_PATH = os.path.join(dataset.location, \"valid\")\n",
        "VALID_DATA_SET_ANN_FILE_PATH = os.path.join(dataset.location, \"valid\", ANNOTATIONS_FILE_NAME)\n",
        "\n",
        "register_coco_instances(\n",
        "    name=VALID_DATA_SET_NAME,\n",
        "    metadata={},\n",
        "    json_file=VALID_DATA_SET_ANN_FILE_PATH,\n",
        "    image_root=VALID_DATA_SET_IMAGES_DIR_PATH\n",
        ")\n",
        "\n",
        "# Configuración del modelo\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (TRAIN_DATA_SET_NAME,)\n",
        "cfg.DATASETS.TEST = (VALID_DATA_SET_NAME,)\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.001\n",
        "cfg.SOLVER.MAX_ITER = 3000\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 7  # Número de categorías de microplásticos\n",
        "\n",
        "\n",
        "# Creación del entrenador\n",
        "trainer = DefaultTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()\n",
        "\n",
        "# Configuración del modelo\n",
        "cfg.MODEL.WEIGHTS = \"./output/model_final.pth\"  # Ruta a los pesos del modelo entrenado\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7  # Umbral para la predicción\n",
        "cfg.DATASETS.TEST = (\"microplastic-dataset-valid\", )\n",
        "\n",
        "predictor = DefaultPredictor(cfg) #Predictor\n",
        "\n",
        "# Ruta para guardar el archivo CSV\n",
        "archivo_csv = 'microplastico_y_ubicaciones.csv'\n",
        "\n",
        "# Leer la imagen\n",
        "image_path = os.path.join(VALID_DATA_SET_IMAGES_DIR_PATH, uploaded_file)\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "if image is None:\n",
        "    raise FileNotFoundError(f\"La imagen '{uploaded_file}' no se encuentra en la ruta '{VALID_DATA_SET_IMAGES_DIR_PATH}'.\")\n",
        "\n",
        "# Detectar microplásticos\n",
        "outputs = predictor(image)\n",
        "instances = outputs[\"instances\"].to(\"cpu\")\n",
        "pred_boxes = instances.pred_boxes.tensor.numpy()  # Coordenadas de las cajas delimitadoras\n",
        "\n",
        "# Convertir la imagen a HSV\n",
        "hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "# Definir los rangos de color en HSV\n",
        "color_ranges = {\n",
        "    \"Verde\": ((0, 0, 200), (180, 30, 255)),\n",
        "    \"Azul\": ((100, 150, 0), (140, 255, 255)),\n",
        "    \"Amarillo\": ((20, 100, 100), (30, 255, 255)),\n",
        "    \"Blanco\": ((40, 40, 40), (80, 255, 255)),\n",
        "    \"Rojo\": ((0, 100, 100), (10, 255, 255)),\n",
        "}\n",
        "\n",
        "# Contar los microplásticos por color\n",
        "color_counts = {color: 0 for color in color_ranges}\n",
        "\n",
        "# Función para encontrar el color más cercano\n",
        "def get_closest_color(hsv_image, x, y, w, h):\n",
        "    roi = hsv_image[y:y+h, x:x+w]\n",
        "    mean_color = cv2.mean(roi)[:3]\n",
        "    min_dist = float('inf')\n",
        "    closest_color = None\n",
        "    for color, (lower, upper) in color_ranges.items():\n",
        "        lower_bound = np.array(lower, dtype=\"uint8\")\n",
        "        upper_bound = np.array(upper, dtype=\"uint8\")\n",
        "        mask = cv2.inRange(hsv_image, lower_bound, upper_bound)\n",
        "        mask_mean_color = cv2.mean(hsv_image, mask=mask)[:3]\n",
        "        dist = np.linalg.norm(np.array(mean_color) - np.array(mask_mean_color))\n",
        "        if dist < min_dist:\n",
        "            min_dist = dist\n",
        "            closest_color = color\n",
        "    return closest_color\n",
        "\n",
        "# Contar y asignar colores a cada microplástico detectado\n",
        "microplastico_data = []\n",
        "for box in pred_boxes:\n",
        "    x1, y1, x2, y2 = box\n",
        "    x, y, w, h = int(x1), int(y1), int(x2 - x1), int(y2 - y1)\n",
        "    color = get_closest_color(hsv_image, x, y, w, h)\n",
        "    if color:\n",
        "        color_counts[color] += 1\n",
        "        # Dibujar la caja delimitadora y el color en la imagen\n",
        "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "        cv2.putText(image, color, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "        # Agregar los datos al microplastico_data\n",
        "        microplastico_data.append([color, x, y, w, h])\n",
        "\n",
        "# Solicitar al usuario que ingrese el nombre del archivo de imagen\n",
        "st.markdown(\"\"\"\n",
        "    <style>\n",
        "    .center {\n",
        "        display: flex;\n",
        "        justify-content: center;\n",
        "    }\n",
        "    </style>\n",
        "    <div class=\"center\">\n",
        "        <h2>Sube tu imagen</h2>\n",
        "    </div>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "uploaded_file = st.file_uploader(\" \", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "# Ubicación en el mapa\n",
        "st.markdown(\"\"\"\n",
        "    <style>\n",
        "    .center {\n",
        "        display: flex;\n",
        "        justify-content: center;\n",
        "    }\n",
        "    </style>\n",
        "    <div class=\"center\">\n",
        "        <h2>Ingresa tu ubicación</h2>\n",
        "    </div>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "def solicitar_datos():\n",
        "  latitud = st.number_input('Latitud', value=0.0, format=\"%.6f\")\n",
        "  longitud = st.number_input('Longitud', value=0.0, format=\"%.6f\")\n",
        "  descripcion = st.text_input('Descripción de la ubicación (opcional)')\n",
        "\n",
        "  # Ubicación en el mapa\n",
        "  st.markdown(\"\"\"\n",
        "      <style>\n",
        "      .center {\n",
        "          display: flex;\n",
        "          justify-content: center;\n",
        "      }\n",
        "      </style>\n",
        "      <div class=\"center\">\n",
        "          <h2>Ubicación en el mapa</h2>\n",
        "      </div>\n",
        "      \"\"\", unsafe_allow_html=True)\n",
        "  st.map(pd.DataFrame({'lat': [latitud], 'lon': [longitud], 'zoom': [1]}))\n",
        "\n",
        "# Solicitar los datos\n",
        "ubicacion_data = []\n",
        "entrada = solicitar_datos()\n",
        "if entrada:\n",
        "    ubicacion_data.append(entrada)\n",
        "\n",
        "# Contar los microplásticos por color y exportar a CSV\n",
        "data = {\n",
        "    \"Color\": [],\n",
        "    \"Conteo\": []\n",
        "}\n",
        "\n",
        "total_microplasticos = 0\n",
        "for color, count in color_counts.items():\n",
        "    if count > 0:\n",
        "        data[\"Color\"].append(color)\n",
        "        data[\"Conteo\"].append(count)\n",
        "        total_microplasticos += count\n",
        "\n",
        "# Agregar el total de microplásticos\n",
        "data[\"Color\"].append(\"Total\")\n",
        "data[\"Conteo\"].append(total_microplasticos)\n",
        "\n",
        "# Convertir a DataFrame y exportar a CSV\n",
        "df_microplastico = pd.DataFrame(data)\n",
        "\n",
        "# Agregar los datos de microplásticos y ubicaciones en el mismo CSV\n",
        "df_ubicaciones = pd.DataFrame(ubicacion_data, columns=[\"Latitud\", \"Longitud\", \"País\", \"Descripción\"])\n",
        "df_final = pd.concat([df_microplastico, df_ubicaciones], axis=1)\n",
        "\n",
        "df_final.to_csv(archivo_csv, index=False)\n",
        "\n",
        "st.write(f\"Los datos se han guardado en '{archivo_csv}'.\")\n",
        "\n",
        "# Imprimir el resumen del conteo\n",
        "st.write(\"Resumen del conteo de microplásticos:\")\n",
        "for color, count in color_counts.items():\n",
        "    st.write(f\"{color}: {count}\")\n",
        "\n",
        "# Imprimir el total de microplásticos\n",
        "st.write(f\"Total de microplásticos: {total_microplasticos}\")\n",
        "\n",
        "# Guardar la imagen con los rectángulos dibujados\n",
        "output_image_path = os.path.join(VALID_DATA_SET_IMAGES_DIR_PATH, 'image_with_boxes.jpg')\n",
        "cv2.imwrite(output_image_path, image)\n",
        "st.write(f\"Imagen con los rectángulos guardada en '{output_image_path}'.\")\n",
        "\n",
        "# Mostrar la imagen con las cajas delimitadoras y colores\n",
        "cv2_imshow(image)  # Utiliza cv2.imshow en otros entornos\n",
        "st.write(\"df_final\")\n",
        "\n",
        "st.write(\"¡Gracias! :)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEDvuxVMYl7w",
        "outputId": "7128acb6-7592-4b1c-ecda-feff7127890c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "[07/21 00:55:38 d2.engine.defaults]: Model:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=8, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=28, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "WARNING [07/21 00:55:38 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[07/21 00:55:38 d2.data.datasets.coco]: Loaded 577 images in COCO format from /content/Microplastic-Dataset-19/train/_annotations.coco.json\n",
            "[07/21 00:55:38 d2.data.build]: Removed 0 images with no usable annotations. 577 images left.\n",
            "[07/21 00:55:38 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "[07/21 00:55:38 d2.data.build]: Using training sampler TrainingSampler\n",
            "[07/21 00:55:38 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[07/21 00:55:38 d2.data.common]: Serializing 577 elements to byte tensors and concatenating them all ...\n",
            "[07/21 00:55:38 d2.data.common]: Serialized dataset takes 0.30 MiB\n",
            "[07/21 00:55:38 d2.data.build]: Making batched data loader with batch_size=2\n",
            "WARNING [07/21 00:55:38 d2.solver.build]: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
            "[07/21 00:55:38 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (8, 1024) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (28, 1024) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (28,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Some model parameters or buffers are not found in the checkpoint:\n",
            "roi_heads.box_predictor.bbox_pred.{bias, weight}\n",
            "roi_heads.box_predictor.cls_score.{bias, weight}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07/21 00:55:39 d2.engine.train_loop]: Starting training from iteration 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07/21 00:55:46 d2.utils.events]:  eta: 0:16:45  iter: 19  total_loss: 3.703  loss_cls: 1.971  loss_box_reg: 0.7059  loss_rpn_cls: 1.106  loss_rpn_loc: 0.09794    time: 0.3286  last_time: 0.3657  data_time: 0.0204  last_data_time: 0.0204   lr: 1.9981e-05  max_mem: 2009M\n",
            "[07/21 00:55:52 d2.utils.events]:  eta: 0:16:34  iter: 39  total_loss: 2.89  loss_cls: 1.611  loss_box_reg: 0.8148  loss_rpn_cls: 0.4493  loss_rpn_loc: 0.119    time: 0.3307  last_time: 0.3700  data_time: 0.0142  last_data_time: 0.0057   lr: 3.9961e-05  max_mem: 2009M\n",
            "[07/21 00:55:59 d2.utils.events]:  eta: 0:16:31  iter: 59  total_loss: 2.356  loss_cls: 1.131  loss_box_reg: 0.8071  loss_rpn_cls: 0.1267  loss_rpn_loc: 0.1383    time: 0.3328  last_time: 0.3671  data_time: 0.0099  last_data_time: 0.0333   lr: 5.9941e-05  max_mem: 2010M\n",
            "[07/21 00:56:06 d2.utils.events]:  eta: 0:16:27  iter: 79  total_loss: 1.802  loss_cls: 0.6997  loss_box_reg: 0.8077  loss_rpn_cls: 0.1254  loss_rpn_loc: 0.07303    time: 0.3365  last_time: 0.3668  data_time: 0.0102  last_data_time: 0.0060   lr: 7.9921e-05  max_mem: 2010M\n",
            "[07/21 00:56:12 d2.utils.events]:  eta: 0:16:15  iter: 99  total_loss: 1.539  loss_cls: 0.5543  loss_box_reg: 0.8093  loss_rpn_cls: 0.07667  loss_rpn_loc: 0.06174    time: 0.3331  last_time: 0.3363  data_time: 0.0106  last_data_time: 0.0201   lr: 9.9901e-05  max_mem: 2010M\n",
            "[07/21 00:56:19 d2.utils.events]:  eta: 0:16:05  iter: 119  total_loss: 1.308  loss_cls: 0.4141  loss_box_reg: 0.7493  loss_rpn_cls: 0.07312  loss_rpn_loc: 0.05875    time: 0.3333  last_time: 0.3297  data_time: 0.0116  last_data_time: 0.0120   lr: 0.00011988  max_mem: 2010M\n",
            "[07/21 00:56:26 d2.utils.events]:  eta: 0:15:59  iter: 139  total_loss: 1.354  loss_cls: 0.4087  loss_box_reg: 0.7983  loss_rpn_cls: 0.08511  loss_rpn_loc: 0.07771    time: 0.3340  last_time: 0.3132  data_time: 0.0087  last_data_time: 0.0057   lr: 0.00013986  max_mem: 2010M\n",
            "[07/21 00:56:32 d2.utils.events]:  eta: 0:15:55  iter: 159  total_loss: 1.294  loss_cls: 0.3277  loss_box_reg: 0.8014  loss_rpn_cls: 0.05705  loss_rpn_loc: 0.07101    time: 0.3338  last_time: 0.2482  data_time: 0.0150  last_data_time: 0.0146   lr: 0.00015984  max_mem: 2010M\n",
            "[07/21 00:56:39 d2.utils.events]:  eta: 0:15:44  iter: 179  total_loss: 1.347  loss_cls: 0.3673  loss_box_reg: 0.7497  loss_rpn_cls: 0.0816  loss_rpn_loc: 0.1055    time: 0.3326  last_time: 0.3158  data_time: 0.0089  last_data_time: 0.0134   lr: 0.00017982  max_mem: 2010M\n",
            "[07/21 00:56:46 d2.utils.events]:  eta: 0:15:38  iter: 199  total_loss: 1.187  loss_cls: 0.3188  loss_box_reg: 0.721  loss_rpn_cls: 0.05687  loss_rpn_loc: 0.06037    time: 0.3327  last_time: 0.3545  data_time: 0.0113  last_data_time: 0.0056   lr: 0.0001998  max_mem: 2010M\n",
            "[07/21 00:56:52 d2.utils.events]:  eta: 0:15:30  iter: 219  total_loss: 1.144  loss_cls: 0.3243  loss_box_reg: 0.709  loss_rpn_cls: 0.0464  loss_rpn_loc: 0.05738    time: 0.3316  last_time: 0.3353  data_time: 0.0101  last_data_time: 0.0137   lr: 0.00021978  max_mem: 2011M\n",
            "[07/21 00:56:59 d2.utils.events]:  eta: 0:15:24  iter: 239  total_loss: 1.124  loss_cls: 0.3195  loss_box_reg: 0.6634  loss_rpn_cls: 0.06043  loss_rpn_loc: 0.06253    time: 0.3329  last_time: 0.2764  data_time: 0.0149  last_data_time: 0.0121   lr: 0.00023976  max_mem: 2011M\n",
            "[07/21 00:57:05 d2.utils.events]:  eta: 0:15:16  iter: 259  total_loss: 1.128  loss_cls: 0.3195  loss_box_reg: 0.685  loss_rpn_cls: 0.0556  loss_rpn_loc: 0.07109    time: 0.3322  last_time: 0.2859  data_time: 0.0087  last_data_time: 0.0060   lr: 0.00025974  max_mem: 2011M\n",
            "[07/21 00:57:12 d2.utils.events]:  eta: 0:15:10  iter: 279  total_loss: 0.9493  loss_cls: 0.2593  loss_box_reg: 0.5966  loss_rpn_cls: 0.03117  loss_rpn_loc: 0.04798    time: 0.3322  last_time: 0.3280  data_time: 0.0110  last_data_time: 0.0066   lr: 0.00027972  max_mem: 2011M\n",
            "[07/21 00:57:19 d2.utils.events]:  eta: 0:15:03  iter: 299  total_loss: 1.091  loss_cls: 0.3167  loss_box_reg: 0.6459  loss_rpn_cls: 0.04655  loss_rpn_loc: 0.07886    time: 0.3319  last_time: 0.3701  data_time: 0.0089  last_data_time: 0.0121   lr: 0.0002997  max_mem: 2011M\n",
            "[07/21 00:57:25 d2.utils.events]:  eta: 0:14:55  iter: 319  total_loss: 1.006  loss_cls: 0.2748  loss_box_reg: 0.5807  loss_rpn_cls: 0.05523  loss_rpn_loc: 0.07531    time: 0.3313  last_time: 0.3617  data_time: 0.0162  last_data_time: 0.0277   lr: 0.00031968  max_mem: 2011M\n",
            "[07/21 00:57:32 d2.utils.events]:  eta: 0:14:45  iter: 339  total_loss: 1.07  loss_cls: 0.3039  loss_box_reg: 0.6405  loss_rpn_cls: 0.02968  loss_rpn_loc: 0.04274    time: 0.3309  last_time: 0.3251  data_time: 0.0114  last_data_time: 0.0182   lr: 0.00033966  max_mem: 2011M\n",
            "[07/21 00:57:38 d2.utils.events]:  eta: 0:14:40  iter: 359  total_loss: 0.8808  loss_cls: 0.2303  loss_box_reg: 0.546  loss_rpn_cls: 0.03097  loss_rpn_loc: 0.02795    time: 0.3314  last_time: 0.3879  data_time: 0.0158  last_data_time: 0.0250   lr: 0.00035964  max_mem: 2011M\n",
            "[07/21 00:57:45 d2.utils.events]:  eta: 0:14:31  iter: 379  total_loss: 0.9409  loss_cls: 0.2573  loss_box_reg: 0.5738  loss_rpn_cls: 0.03255  loss_rpn_loc: 0.05065    time: 0.3311  last_time: 0.3667  data_time: 0.0102  last_data_time: 0.0123   lr: 0.00037962  max_mem: 2011M\n",
            "[07/21 00:57:51 d2.utils.events]:  eta: 0:14:23  iter: 399  total_loss: 0.948  loss_cls: 0.2799  loss_box_reg: 0.5547  loss_rpn_cls: 0.04114  loss_rpn_loc: 0.06267    time: 0.3308  last_time: 0.3253  data_time: 0.0106  last_data_time: 0.0060   lr: 0.0003996  max_mem: 2011M\n",
            "[07/21 00:57:58 d2.utils.events]:  eta: 0:14:17  iter: 419  total_loss: 1.048  loss_cls: 0.2914  loss_box_reg: 0.6483  loss_rpn_cls: 0.04417  loss_rpn_loc: 0.05024    time: 0.3306  last_time: 0.3238  data_time: 0.0108  last_data_time: 0.0054   lr: 0.00041958  max_mem: 2011M\n",
            "[07/21 00:58:05 d2.utils.events]:  eta: 0:14:10  iter: 439  total_loss: 1.02  loss_cls: 0.2708  loss_box_reg: 0.5897  loss_rpn_cls: 0.04645  loss_rpn_loc: 0.05856    time: 0.3303  last_time: 0.3678  data_time: 0.0128  last_data_time: 0.0056   lr: 0.00043956  max_mem: 2011M\n",
            "[07/21 00:58:11 d2.utils.events]:  eta: 0:14:03  iter: 459  total_loss: 0.9408  loss_cls: 0.2451  loss_box_reg: 0.5528  loss_rpn_cls: 0.02649  loss_rpn_loc: 0.05484    time: 0.3302  last_time: 0.3132  data_time: 0.0102  last_data_time: 0.0048   lr: 0.00045954  max_mem: 2011M\n",
            "[07/21 00:58:17 d2.utils.events]:  eta: 0:13:55  iter: 479  total_loss: 0.9133  loss_cls: 0.2493  loss_box_reg: 0.5966  loss_rpn_cls: 0.0314  loss_rpn_loc: 0.05171    time: 0.3296  last_time: 0.3490  data_time: 0.0091  last_data_time: 0.0271   lr: 0.00047952  max_mem: 2011M\n",
            "[07/21 00:58:24 d2.utils.events]:  eta: 0:13:48  iter: 499  total_loss: 1.071  loss_cls: 0.3063  loss_box_reg: 0.6118  loss_rpn_cls: 0.03708  loss_rpn_loc: 0.04604    time: 0.3297  last_time: 0.3652  data_time: 0.0150  last_data_time: 0.0139   lr: 0.0004995  max_mem: 2011M\n",
            "[07/21 00:58:30 d2.utils.events]:  eta: 0:13:41  iter: 519  total_loss: 0.9254  loss_cls: 0.2756  loss_box_reg: 0.5692  loss_rpn_cls: 0.0237  loss_rpn_loc: 0.04886    time: 0.3294  last_time: 0.3175  data_time: 0.0089  last_data_time: 0.0133   lr: 0.00051948  max_mem: 2011M\n",
            "[07/21 00:58:38 d2.utils.events]:  eta: 0:13:37  iter: 539  total_loss: 1.03  loss_cls: 0.2832  loss_box_reg: 0.592  loss_rpn_cls: 0.0608  loss_rpn_loc: 0.086    time: 0.3316  last_time: 0.2400  data_time: 0.0206  last_data_time: 0.0061   lr: 0.00053946  max_mem: 2011M\n",
            "[07/21 00:58:45 d2.utils.events]:  eta: 0:13:30  iter: 559  total_loss: 0.8964  loss_cls: 0.2553  loss_box_reg: 0.5546  loss_rpn_cls: 0.03594  loss_rpn_loc: 0.06199    time: 0.3319  last_time: 0.3231  data_time: 0.0113  last_data_time: 0.0058   lr: 0.00055944  max_mem: 2011M\n",
            "[07/21 00:58:52 d2.utils.events]:  eta: 0:13:23  iter: 579  total_loss: 0.913  loss_cls: 0.268  loss_box_reg: 0.5823  loss_rpn_cls: 0.02227  loss_rpn_loc: 0.05027    time: 0.3324  last_time: 0.3301  data_time: 0.0149  last_data_time: 0.0257   lr: 0.00057942  max_mem: 2011M\n",
            "[07/21 00:58:59 d2.utils.events]:  eta: 0:13:17  iter: 599  total_loss: 0.9699  loss_cls: 0.2889  loss_box_reg: 0.5688  loss_rpn_cls: 0.03381  loss_rpn_loc: 0.06492    time: 0.3324  last_time: 0.3118  data_time: 0.0104  last_data_time: 0.0056   lr: 0.0005994  max_mem: 2011M\n",
            "[07/21 00:59:05 d2.utils.events]:  eta: 0:13:10  iter: 619  total_loss: 0.9042  loss_cls: 0.2375  loss_box_reg: 0.4944  loss_rpn_cls: 0.02399  loss_rpn_loc: 0.04647    time: 0.3323  last_time: 0.3572  data_time: 0.0113  last_data_time: 0.0054   lr: 0.00061938  max_mem: 2011M\n",
            "[07/21 00:59:12 d2.utils.events]:  eta: 0:13:03  iter: 639  total_loss: 0.9797  loss_cls: 0.2623  loss_box_reg: 0.5818  loss_rpn_cls: 0.04272  loss_rpn_loc: 0.102    time: 0.3321  last_time: 0.3566  data_time: 0.0097  last_data_time: 0.0054   lr: 0.00063936  max_mem: 2011M\n",
            "[07/21 00:59:19 d2.utils.events]:  eta: 0:12:57  iter: 659  total_loss: 0.8973  loss_cls: 0.2412  loss_box_reg: 0.542  loss_rpn_cls: 0.0229  loss_rpn_loc: 0.04119    time: 0.3324  last_time: 0.3283  data_time: 0.0157  last_data_time: 0.0056   lr: 0.00065934  max_mem: 2011M\n",
            "[07/21 00:59:25 d2.utils.events]:  eta: 0:12:50  iter: 679  total_loss: 0.8826  loss_cls: 0.2557  loss_box_reg: 0.5131  loss_rpn_cls: 0.03223  loss_rpn_loc: 0.03007    time: 0.3322  last_time: 0.3134  data_time: 0.0087  last_data_time: 0.0057   lr: 0.00067932  max_mem: 2011M\n",
            "[07/21 00:59:32 d2.utils.events]:  eta: 0:12:43  iter: 699  total_loss: 0.9482  loss_cls: 0.2603  loss_box_reg: 0.5922  loss_rpn_cls: 0.03674  loss_rpn_loc: 0.07292    time: 0.3320  last_time: 0.3138  data_time: 0.0111  last_data_time: 0.0119   lr: 0.0006993  max_mem: 2011M\n",
            "[07/21 00:59:38 d2.utils.events]:  eta: 0:12:37  iter: 719  total_loss: 1.063  loss_cls: 0.2727  loss_box_reg: 0.6171  loss_rpn_cls: 0.03472  loss_rpn_loc: 0.07141    time: 0.3318  last_time: 0.3597  data_time: 0.0091  last_data_time: 0.0063   lr: 0.00071928  max_mem: 2011M\n",
            "[07/21 00:59:45 d2.utils.events]:  eta: 0:12:30  iter: 739  total_loss: 0.9391  loss_cls: 0.2643  loss_box_reg: 0.5497  loss_rpn_cls: 0.03151  loss_rpn_loc: 0.05583    time: 0.3319  last_time: 0.3868  data_time: 0.0137  last_data_time: 0.0269   lr: 0.00073926  max_mem: 2011M\n",
            "[07/21 00:59:52 d2.utils.events]:  eta: 0:12:23  iter: 759  total_loss: 0.946  loss_cls: 0.2715  loss_box_reg: 0.6077  loss_rpn_cls: 0.04029  loss_rpn_loc: 0.04651    time: 0.3318  last_time: 0.2466  data_time: 0.0117  last_data_time: 0.0056   lr: 0.00075924  max_mem: 2011M\n",
            "[07/21 00:59:58 d2.utils.events]:  eta: 0:12:17  iter: 779  total_loss: 0.8775  loss_cls: 0.2424  loss_box_reg: 0.5576  loss_rpn_cls: 0.0247  loss_rpn_loc: 0.03201    time: 0.3320  last_time: 0.3758  data_time: 0.0124  last_data_time: 0.0134   lr: 0.00077922  max_mem: 2011M\n",
            "[07/21 01:00:05 d2.utils.events]:  eta: 0:12:10  iter: 799  total_loss: 0.832  loss_cls: 0.2574  loss_box_reg: 0.5101  loss_rpn_cls: 0.03014  loss_rpn_loc: 0.03461    time: 0.3316  last_time: 0.3232  data_time: 0.0108  last_data_time: 0.0065   lr: 0.0007992  max_mem: 2011M\n",
            "[07/21 01:00:11 d2.utils.events]:  eta: 0:12:03  iter: 819  total_loss: 1.003  loss_cls: 0.299  loss_box_reg: 0.5832  loss_rpn_cls: 0.04223  loss_rpn_loc: 0.06923    time: 0.3314  last_time: 0.2694  data_time: 0.0117  last_data_time: 0.0257   lr: 0.00081918  max_mem: 2011M\n"
          ]
        }
      ]
    }
  ]
}